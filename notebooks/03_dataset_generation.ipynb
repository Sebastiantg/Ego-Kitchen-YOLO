{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "158172ea",
   "metadata": {},
   "source": [
    "# 03 — Dataset Generation (YOLO Format)\n",
    "\n",
    "**Goal:**  \n",
    "Generate a YOLOv8-compatible dataset for fine-tuning using selected classes from EPIC-KITCHENS.\n",
    "\n",
    "This notebook:\n",
    "1. Loads the main EPIC-KITCHENS annotation CSV  \n",
    "2. Filters relevant classes  \n",
    "3. Parses bounding boxes  \n",
    "4. Creates a balanced subset  \n",
    "5. Splits into `train` and `val`  \n",
    "6. Writes YOLO `.txt` labels and dataset YAML file  \n",
    "\n",
    "**Based on:** `train_dataset_img.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ba3c11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Configuration loaded:\n",
      "DATA_ROOT: ../annotations\n",
      "CLASSES: {'bread': ['bread', 'bread package', 'bread packaging'], 'knife': ['knife', 'mezzaluna knife', 'mincing knife']}\n",
      "OUTPUT_DIR: ./data/epic_train_subset\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import ast\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from config import DATA_ROOT, FRAMES_ROOT, ANNOTATION_CSV, CLASS_MAPPING,CLASSES, MAX_PER_CLASS, TRAIN_SPLIT, IMG_EXT, IMG_WIDTH, IMG_HEIGHT, OUTPUT_DIR\n",
    "\n",
    "CLASSES = [\"bread\", \"knife\"]\n",
    "\n",
    "print(f\"Configuration loaded:\\nDATA_ROOT: {DATA_ROOT}\\nCLASSES: {CLASS_MAPPING}\\nOUTPUT_DIR: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a554bfca",
   "metadata": {},
   "source": [
    "## Step 1 — Load and Filter the Annotations\n",
    "We start by loading the CSV annotation file and filtering out any irrelevant or invalid entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6644c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 389811 total annotations\n",
      "Filtered 10811 annotations for selected classes: bread, bread package, bread packaging, knife, mezzaluna knife, mincing knife\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(ANNOTATION_CSV)\n",
    "print(f\"Loaded {len(df)} total annotations\")\n",
    "\n",
    "# Keep only classes of interest\n",
    "target_nouns = sum(CLASS_MAPPING.values(), [])\n",
    "df = df[df[\"noun\"].isin(target_nouns)]\n",
    "print(f\"Filtered {len(df)} annotations for selected classes: {', '.join(target_nouns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "caf446b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10811 annotations for selected classes: knife, bread, bread packaging, mincing knife, mezzaluna knife, bread package\n"
     ]
    }
   ],
   "source": [
    "def map_to_base(noun):\n",
    "    for base, synonyms in CLASS_MAPPING.items():\n",
    "        if noun in synonyms:\n",
    "            return base\n",
    "    return None\n",
    "\n",
    "df[\"base_class\"] = df[\"noun\"].apply(map_to_base)\n",
    "print(f\"Found {len(df)} annotations for selected classes: {', '.join(df['noun'].unique())}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b22105",
   "metadata": {},
   "source": [
    "## Step 2 — Parse and Validate Bounding Boxes\n",
    "\n",
    "Bounding boxes are stored as text (e.g. `'[(top, left, height, width)]'`).  \n",
    "We parse them safely and filter out invalid or empty entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c477b804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Remaining rows with valid bounding boxes: 7983\n"
     ]
    }
   ],
   "source": [
    "def parse_bboxes(bbox_str):\n",
    "    \"\"\"Parse YOLO-style bounding boxes stored as string tuples.\"\"\"\n",
    "    try:\n",
    "        bboxes = ast.literal_eval(bbox_str)\n",
    "        if not isinstance(bboxes, list) or len(bboxes) == 0:\n",
    "            return []\n",
    "        valid_bboxes = [box for box in bboxes if isinstance(box, (list, tuple)) and len(box) == 4]\n",
    "        return valid_bboxes\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "df[\"parsed_bboxes\"] = df[\"bounding_boxes\"].apply(parse_bboxes)\n",
    "df = df[df[\"parsed_bboxes\"].map(lambda x: isinstance(x, list) and len(x) > 0)]\n",
    "print(f\" Remaining rows with valid bounding boxes: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36eedc3e",
   "metadata": {},
   "source": [
    "## Step 3 — Balance the Dataset per Class\n",
    "\n",
    "Limit the number of samples per class (`MAX_PER_CLASS`) to keep the dataset balanced and lightweight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1ab5530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Balanced subset created: 2000 samples total (bread, knife)\n"
     ]
    }
   ],
   "source": [
    "subset = []\n",
    "for c in CLASSES:\n",
    "    class_df = df[df[\"base_class\"] == c]\n",
    "    subset.append(class_df.sample(min(len(class_df), MAX_PER_CLASS), random_state=42))\n",
    "df = pd.concat(subset).reset_index(drop=True)\n",
    "print(f\" Balanced subset created: {len(df)} samples total ({', '.join(CLASSES)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad89ce54",
   "metadata": {},
   "source": [
    "## Step 4 — Split into Train and Validation Sets\n",
    "We divide the dataset into 90% training and 10% validation using stratified sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "019e0099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split complete → Train: 1800  |  Val: 200\n"
     ]
    }
   ],
   "source": [
    "VAL_SPLIT = 1 - TRAIN_SPLIT\n",
    "train_df, val_df = train_test_split(df, test_size=VAL_SPLIT, stratify=df[\"base_class\"], random_state=42)\n",
    "print(f\"Split complete → Train: {len(train_df)}  |  Val: {len(val_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fb98f2",
   "metadata": {},
   "source": [
    "##  Step 5 — Create Output Folder Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c751ae62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Folder structure created under: ./data/epic_train_subset\n"
     ]
    }
   ],
   "source": [
    "for split in [\"train\", \"val\"]:\n",
    "    os.makedirs(f\"{OUTPUT_DIR}/{split}/images\", exist_ok=True)\n",
    "    os.makedirs(f\"{OUTPUT_DIR}/{split}/labels\", exist_ok=True)\n",
    "\n",
    "print(f\" Folder structure created under: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c327873f",
   "metadata": {},
   "source": [
    "## Step 6 — Generate YOLO Labels and Copy Images\n",
    "Each image is copied to its split folder, and bounding boxes are saved in YOLO format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5309c370",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_id = {cls: i for i, cls in enumerate(CLASSES)}\n",
    "\n",
    "def process_split(split_name, split_df):\n",
    "    print(f\"\\n Processing {split_name.upper()} ({len(split_df)} samples)\")\n",
    "    stats_requested = defaultdict(lambda: defaultdict(int))\n",
    "    stats_copied = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "    for _, row in tqdm(split_df.iterrows(), total=len(split_df)):\n",
    "        participant = row[\"participant_id\"]\n",
    "        video_id = row[\"video_id\"]\n",
    "        frame = int(row[\"frame\"])\n",
    "        base_class = row[\"noun\"]\n",
    "        valid_bboxes = row[\"parsed_bboxes\"]\n",
    "\n",
    "        stats_requested[base_class][video_id] += 1\n",
    "\n",
    "        # Build source image path\n",
    "        frame_name = f\"{frame:010d}{IMG_EXT}\"\n",
    "        src_img = os.path.join(FRAMES_ROOT, participant, \"object_detection_images\", video_id, frame_name)\n",
    "        if not os.path.exists(src_img):\n",
    "            continue\n",
    "\n",
    "        # Output paths\n",
    "        img_name = f\"{participant}_{video_id}_{frame}{IMG_EXT}\"\n",
    "        dst_img = os.path.join(OUTPUT_DIR, f\"{split_name}/images\", img_name)\n",
    "        label_path = os.path.join(OUTPUT_DIR, f\"{split_name}/labels\", img_name.replace(IMG_EXT, \".txt\"))\n",
    "\n",
    "        shutil.copy(src_img, dst_img)\n",
    "        stats_copied[base_class][video_id] += 1\n",
    "\n",
    "        # Write YOLO label\n",
    "        lines = []\n",
    "        for box in valid_bboxes:\n",
    "            if not isinstance(box, (list, tuple)) or len(box) != 4:\n",
    "                continue\n",
    "            top, left, height, width = map(float, box)\n",
    "            xc = left + width / 2\n",
    "            yc = top + height / 2\n",
    "            xc_n, yc_n, wn, hn = xc / IMG_WIDTH, yc / IMG_HEIGHT, width / IMG_WIDTH, height / IMG_HEIGHT\n",
    "            cls_id = class_to_id[base_class]\n",
    "            lines.append(f\"{cls_id} {xc_n:.6f} {yc_n:.6f} {wn:.6f} {hn:.6f}\\n\")\n",
    "\n",
    "        if len(lines) > 0:\n",
    "            with open(label_path, \"w\") as f:\n",
    "                f.writelines(lines)\n",
    "\n",
    "    # Summary per class\n",
    "    print(f\"\\n === {split_name.upper()} SUMMARY ===\")\n",
    "    for cls in CLASSES:\n",
    "        total_req = sum(stats_requested[cls].values())\n",
    "        total_cop = sum(stats_copied[cls].values())\n",
    "        if total_req == 0:\n",
    "            continue\n",
    "        print(f\"Class '{cls}': {total_cop}/{total_req} images copied ({(total_cop/total_req)*100:.1f}% success)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "feff86ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Processing TRAIN (1800 samples)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1800 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1800/1800 [00:00<00:00, 12173.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " === TRAIN SUMMARY ===\n",
      "Class 'bread': 32/853 images copied (3.8% success)\n",
      "Class 'knife': 132/871 images copied (15.2% success)\n",
      "\n",
      " Processing VAL (200 samples)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 10960.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " === VAL SUMMARY ===\n",
      "Class 'bread': 1/96 images copied (1.0% success)\n",
      "Class 'knife': 19/94 images copied (20.2% success)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "process_split(\"train\", train_df)\n",
    "process_split(\"val\", val_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5499931b",
   "metadata": {},
   "source": [
    "## Step 7 — Generate YOLO Dataset YAML\n",
    "The YAML file defines dataset structure and class list for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37182271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO dataset YAML created at: ./data/epic_train_subset/dataset.yaml\n"
     ]
    }
   ],
   "source": [
    "yaml_content = f\"\"\"\n",
    "path: {OUTPUT_DIR}\n",
    "train: train/images\n",
    "val: val/images\n",
    "nc: {len(CLASSES)}\n",
    "names: {CLASSES}\n",
    "\"\"\"\n",
    "\n",
    "yaml_path = os.path.join(OUTPUT_DIR, \"dataset.yaml\")\n",
    "with open(yaml_path, \"w\") as f:\n",
    "    f.write(yaml_content)\n",
    "\n",
    "print(f\"YOLO dataset YAML created at: {yaml_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38203f33",
   "metadata": {},
   "source": [
    "## Final Summary\n",
    "\n",
    "- **Format:** YOLOv8-compatible (images + labels + dataset.yaml)\n",
    "\n",
    "You can now train the model using:\n",
    "\n",
    "```bash\n",
    "yolo detect train data={OUTPUT_DIR}/dataset.yaml model=yolov8s.pt epochs=100 patience=10 imgsz=640 name=epic_full_epoch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.8.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
